import os
import json
import re
import time
import requests
import opencc
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from tqdm import tqdm

# --- å…¨å±€é…ç½®ä¸åˆå§‹åŒ– ---
timestart = datetime.now()
print(f"ğŸš€ IPTVé¢‘é“åˆ†ç±»ç³»ç»Ÿå¯åŠ¨ @ {timestart.strftime('%Y-%m-%d %H:%M:%S')}")

# --- ä¿®å¤ OpenCC åŠ è½½é—®é¢˜ ---
try:
    CC_CONVERTER = opencc.OpenCC('t2s')
    print("âœ… OpenCCè½¬æ¢å™¨å·²æˆåŠŸåŠ è½½å†…ç½®é…ç½® 't2s'")
except Exception as e:
    print(f"âŒ é”™è¯¯: åŠ è½½OpenCCè½¬æ¢å™¨å¤±è´¥ - {e}")
    class FallbackConverter:
        def convert(self, text):
            trad_to_simp = {
                'å»£': 'å¹¿', 'æ±': 'ä¸œ', 'è¡›': 'å«', 'è¦–': 'è§†', 'è‡º': 'å°',
                'ç£': 'æ¹¾', 'é›»': 'ç”µ', 'è¦–': 'è§†', 'é »': 'é¢‘', 'ç¶œ': 'ç»¼',
                'è—': 'è‰º', 'é«”': 'ä½“', 'è‚²': 'è‚²', 'åœ‹': 'å›½', 'éš›': 'é™…'
            }
            return ''.join(trad_to_simp.get(char, char) for char in text)
    CC_CONVERTER = FallbackConverter()
    print("âœ… ä½¿ç”¨ç®€æ˜“ç®€ç¹è½¬æ¢å™¨")

# åŠ è½½åˆ†ç±»é…ç½®
with open('category_config.json', 'r', encoding='utf-8') as f:
    CATEGORY_CONFIG = json.load(f)

# é…ç½® requests ä¼šè¯
def create_requests_session():
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1'
    })
    retries = Retry(total=5, backoff_factor=0.5, 
                   status_forcelist=[500, 502, 503, 504, 429],
                   allowed_methods=frozenset(['GET', 'POST']))
    adapter = HTTPAdapter(max_retries=retries, pool_connections=100, pool_maxsize=100)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

HTTP_SESSION = create_requests_session()

# é¢‘é“åç§°è§„èŒƒåŒ–é…ç½®
REMOVAL_LIST = [
    "ã€ŒIPV4ã€", "ã€ŒIPV6ã€", "[ipv6]", "[ipv4]", "_ç”µä¿¡", "ç”µä¿¡", "ï¼ˆHDï¼‰", "[è¶…æ¸…]", 
    "é«˜æ¸…", "è¶…æ¸…", "-HD", "(HK)", "AKtv", "@", "IPV6", "ğŸï¸", "ğŸ¦", " ", "[BD]", 
    "[VGA]", "[HD]", "[SD]", "(1080p)", "(720p)", "(480p)", "HD", "FHD", "4K", 
    "8K", "ç›´æ’­", "LIVE", "å®æ—¶", "RTMP", "HLS", "HTTP", "://", "è½¬ç ", "æµç•…", "æµ‹è¯•"
]
REPLACEMENTS = {
    "CCTV-": "CCTV", "CCTV0": "CCTV", "PLUS": "+", "NewTV-": "NewTV", 
    "iHOT-": "iHOT", "NEW": "New", "New_": "New", "ä¸­å¤®": "CCTV", "å¹¿ä¸œä½“è‚²å«è§†": "å¹¿ä¸œä½“è‚²",
    "æ¹–å—ç”µè§†å°": "æ¹–å—å«è§†", "æµ™æ±Ÿç”µè§†å°": "æµ™æ±Ÿå«è§†", "æ±æ–¹è¡›è¦–": "ä¸œæ–¹å«è§†", "å‡¤å‡°ä¸­æ–‡": "å‡¤å‡°å«è§†",
    "å‡¤å‡°èµ„è®¯å°": "å‡¤å‡°èµ„è®¯", "FOXä½“è‚²": "FS", "ESPNä½“è‚²": "ESPN", "DISCOVERYæ¢ç´¢": "æ¢ç´¢é¢‘é“",
    "å›½å®¶åœ°ç†é¢‘é“": "å›½å®¶åœ°ç†", "å†å²é¢‘é“": "å†å²", "HBOç”µå½±": "HBO", "CNNå›½é™…": "CNN"
}

# é¢‘é“åç§°è§„èŒƒåŒ–æ­£åˆ™
CHANNEL_PATTERNS = [
    (r'^(CCTV[\d+]+)(?:[\u4e00-\u9fa5]*)$', r'\1'),  # CCTVæ•°å­—é¢‘é“
    (r'(æ¹–å—|æµ™æ±Ÿ|æ±Ÿè‹|ä¸œæ–¹|åŒ—äº¬|å¹¿ä¸œ|æ·±åœ³|å¤©æ´¥|å±±ä¸œ)(?:å«è§†|ç”µè§†å°)', r'\1å«è§†'),
    (r'(å‡¤å‡°)(?:ä¸­æ–‡|èµ„è®¯|å«è§†)', r'\1å«è§†'),
    (r'(æ˜Ÿç©º|åå¨±|TVB|ç¿¡ç¿ |æ˜ç )(?:å«è§†|å°)', r'\1å«è§†'),
    (r'(HBO|CNN|BBC|NHK|DISCOVERY)(?:\s*[\u4e00-\u9fa5]+)?$', r'\1'),
    (r'(å«è§†|ä½“è‚²|æ–°é—»|ç”µå½±|å¨±ä¹|å¡é€š|å›½é™…|ç»¼åˆ)(?:é¢‘é“|å°)', r'\1é¢‘é“'),
]

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def read_txt_to_array(file_name):
    try:
        with open(file_name, 'r', encoding='utf-8') as file:
            return [line.strip() for line in file if line.strip()]
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ '{file_name}' å‡ºé”™: {e}")
        return []

def load_corrections(filename):
    corrections = {}
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip() and not line.startswith('#'):
                    parts = line.strip().split(',')
                    if len(parts) > 1:
                        correct_name = parts[0].strip()
                        for name in parts[1:]:
                            corrections[name.strip()] = correct_name
    except Exception as e:
        print(f"åŠ è½½çº é”™æ–‡ä»¶ '{filename}' å‡ºé”™: {e}")
    return corrections

def fetch_source_content(url):
    try:
        response = HTTP_SESSION.get(url, timeout=15)
        response.raise_for_status()
        
        content = response.content
        text = None
        for encoding in ['utf-8', 'gbk', 'gb2312', 'iso-8859-1', 'big5']:
            try:
                text = content.decode(encoding)
                if text.strip().startswith("#EXTM3U"):
                    text = convert_m3u_to_txt(text)
                return text
            except UnicodeDecodeError:
                continue
        print(f"è­¦å‘Š: æ— æ³•è§£ç æº {url}")
        return None
    except requests.exceptions.RequestException as e:
        print(f"å¤„ç†URLæºå‡ºé”™: {url} ({e})")
        return None

def convert_m3u_to_txt(m3u_content):
    lines = m3u_content.strip().split('\n')
    txt_lines = []
    channel_name = ""
    for line in lines:
        line = line.strip()
        if line.startswith("#EXTM3U"):
            continue
        if line.startswith("#EXTINF"):
            # æå–é¢‘é“åç§°ï¼Œå»é™¤å¯èƒ½çš„å‚æ•°
            name_part = line.split(',', 1)[-1]
            channel_name = re.sub(r'[^,\w\s\u4e00-\u9fa5]+', '', name_part).strip()
        elif line.startswith("http") or line.startswith("rtmp"):
            if channel_name:
                txt_lines.append(f"{channel_name},{line}")
                channel_name = ""
        elif "#genre#" not in line and "," in line and re.match(r'^[^,]+,[^\s]+://[^\s]+$', line):
            txt_lines.append(line)
    return '\n'.join(txt_lines)

def normalize_channel_name(channel_name):
    """æ·±åº¦è§„èŒƒåŒ–é¢‘é“åç§°"""
    # ç®€ç¹è½¬æ¢
    try:
        simplified_name = CC_CONVERTER.convert(channel_name)
    except Exception:
        simplified_name = channel_name
    
    # ç§»é™¤æ— ç”¨å­—ç¬¦å’Œè¯è¯­
    cleaned_name = simplified_name
    for item in REMOVAL_LIST:
        cleaned_name = cleaned_name.replace(item, "")
    
    # åº”ç”¨æ­£åˆ™è§„èŒƒåŒ–
    for pattern, replacement in CHANNEL_PATTERNS:
        cleaned_name = re.sub(pattern, replacement, cleaned_name)
    
    # åº”ç”¨æ›¿æ¢è§„åˆ™
    for old, new in REPLACEMENTS.items():
        cleaned_name = cleaned_name.replace(old, new)
    
    # ç»Ÿä¸€æ ¼å¼
    cleaned_name = re.sub(r'\s+', '', cleaned_name)  # ç§»é™¤ç©ºæ ¼
    cleaned_name = re.sub(r'[^\w\u4e00-\u9fa5+]', '', cleaned_name)  # ç§»é™¤éä¸­æ–‡/è‹±æ–‡/æ•°å­—å­—ç¬¦
    
    return cleaned_name.strip()

def parse_and_clean_channels(source_content, corrections_name):
    channels = {}
    if not source_content:
        return channels
    
    lines = source_content.strip().split('\n')
    for line in lines:
        line = line.strip()
        if not line or "#genre#" in line or "#EXTINF:" in line:
            continue
        
        try:
            parts = line.split(',', 1)
            if len(parts) < 2:
                continue
                
            raw_name = parts[0].strip()
            channel_url = parts[1].split('$')[0].strip()

            if not channel_url:
                continue
            
            # æ·±åº¦è§„èŒƒåŒ–åç§°
            cleaned_name = normalize_channel_name(raw_name)
            
            # åº”ç”¨çº é”™è¯å…¸
            corrected_name = corrections_name.get(cleaned_name, cleaned_name)
            
            # åˆå¹¶ç›¸åŒé¢‘é“ä¸åŒæ¥æº
            if corrected_name in channels:
                # ä¿ç•™æ›´é•¿çš„URLï¼ˆé€šå¸¸æ›´å®Œæ•´ï¼‰
                if len(channel_url) > len(channels[corrected_name]):
                    channels[corrected_name] = channel_url
            else:
                channels[corrected_name] = channel_url
                
        except Exception as e:
            print(f"è§£æé¢‘é“è¡Œå¤±è´¥: {line} - {e}")
    return channels

def check_channel_availability(channel_info, timeout=2):
    """æ£€æŸ¥é¢‘é“å¯ç”¨æ€§å¹¶è¿”å›å»¶è¿Ÿ"""
    name, url = channel_info
    if "127.0.0.1" in url or "localhost" in url:
        return name, url, 0

    try:
        # å¯¹äºå¯èƒ½çš„å¤§æ–‡ä»¶æµï¼Œä½¿ç”¨HEADæ–¹æ³•å¯èƒ½ä¸åˆé€‚ï¼Œæ”¹ç”¨å¸¦èŒƒå›´çš„GET
        headers = {'Range': 'bytes=0-1', 'Connection': 'close'} if any(ext in url for ext in ['.m3u8', '.flv', '.ts']) else {}
        
        start_time = time.time()
        response = HTTP_SESSION.get(url, headers=headers, timeout=timeout, stream=True, verify=False)
        response.close()  # ç«‹å³å…³é—­è¿æ¥
        end_time = time.time()
        
        latency = int((end_time - start_time) * 1000)
        if response.status_code < 400 or response.status_code == 416:  # 416è¡¨ç¤ºèŒƒå›´è¯·æ±‚æˆåŠŸ
            return name, url, latency
        return name, url, -1
    except Exception:
        return name, url, -1

def classify_channel(channel_name):
    """æ™ºèƒ½åˆ†ç±»é¢‘é“"""
    channel_name_lower = channel_name.lower()
    
    # ç‰¹æ®Šé¢‘é“ä¼˜å…ˆå¤„ç†
    if "æ˜¥æ™š" in channel_name: return "cw"
    if "ç›´æ’­ä¸­å›½" in channel_name: return "zb"
    if any(kw in channel_name_lower for kw in ["mtv", "music", "éŸ³æ¨‚", "æ¼”å”±ä¼š"]): return "mv"
    if any(kw in channel_name_lower for kw in ["radio", "å¹¿æ’­", "fm", "am"]): return "radio"
    if any(kw in channel_name for kw in ["å›çœ‹", "é‡æ’­", "å›æ”¾", "å½•åƒ"]): return "lx"
    
    # éå†æ‰€æœ‰åˆ†ç±»é…ç½®
    for category_type in CATEGORY_CONFIG.values():
        for category_id, info in category_type.items():
            # å…ˆæ£€æŸ¥å­—å…¸ä¸­çš„å®Œæ•´é¢‘é“åç§°
            for dict_name in info.get("dictionary", []):
                if dict_name in channel_name:
                    return category_id
            
            # å†æ£€æŸ¥å…³é”®è¯
            for keyword in info.get("keywords", []):
                if keyword in channel_name_lower:
                    return category_id
                    
    return "other"

def sort_data(order, data):
    order_dict = {name: i for i, name in enumerate(order)}
    return sorted(data, key=lambda line: order_dict.get(line.split(',')[0], len(order)))

def save_files(categorized_lists):
    all_lines = []
    utc_time = datetime.now(timezone.utc)
    beijing_time = utc_time + timedelta(hours=8)
    version = f"{beijing_time.strftime('%Y%m%d %H:%M')},https://gcalic.v.myalicdn.com/gc/wgw05_1/index.m3u8?contentid=2820180516001"
    all_lines.extend([f"æ›´æ–°æ—¶é—´,#genre#", version, ''])

    total_channels = 0

    def add_category(name, lines, dictionary=None):
        nonlocal total_channels
        if lines:
            all_lines.append(f"{name},#genre#")
            sorted_lines = sort_data(dictionary, lines) if dictionary else sorted(lines)
            all_lines.extend(sorted_lines)
            all_lines.append('')
            total_channels += len(lines)

    # æŒ‰åˆ†ç±»ä¼˜å…ˆçº§è¾“å‡º
    for category_type in CATEGORY_CONFIG.values():
        for cat_id, info in category_type.items():
            if cat_id in categorized_lists and categorized_lists[cat_id]:
                add_category(info["name"], categorized_lists[cat_id], info.get("dictionary"))
    
    # ç‰¹æ®Šç±»åˆ«
    add_category("æ˜¥æ™š", categorized_lists.get('cw', []))
    add_category("ç›´æ’­ä¸­å›½", categorized_lists.get('zb', []))
    add_category("éŸ³ä¹MV", categorized_lists.get('mv', []))
    add_category("æ”¶éŸ³æœºé¢‘é“", categorized_lists.get('radio', []))
    add_category("å½•åƒå›æ”¾", categorized_lists.get('lx', []))
    add_category("å…¶ä»–é¢‘é“", categorized_lists.get('other', []))

    final_content = "\n".join(all_lines)

    try:
        with open("live.txt", "w", encoding='utf-8') as f:
            f.write(final_content)
        print("âœ… é¢‘é“æ–‡ä»¶å·²ä¿å­˜: live.txt")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å‡ºé”™: {e}")

    # ç”ŸæˆM3Uæ–‡ä»¶
    try:
        m3u_content = '#EXTM3U x-tvg-url="https://epg.112114.xyz/pp.xml.gz"\n'
        group_title = ""
        for line in final_content.strip().split('\n'):
            if not line.strip(): continue
            if "#genre#" in line:
                group_title = line.split(',')[0]
                continue
            if "," in line:
                name, url = line.split(',', 1)
                logo = f"https://epg.112114.xyz/logo/{name}.png"
                m3u_content += f'#EXTINF:-1 tvg-name="{name}" tvg-logo="{logo}" group-title="{group_title}",{name}\n{url}\n'
        
        with open("live.m3u", "w", encoding='utf-8') as f:
            f.write(m3u_content)
        print("âœ… M3Uæ–‡ä»¶å·²ä¿å­˜: live.m3u")
    except Exception as e:
        print(f"âŒ ç”ŸæˆM3Uæ–‡ä»¶å‡ºé”™: {e}")

    return total_channels

# --- ä¸»æ‰§è¡Œæµç¨‹ ---

def main():
    print("â¡ï¸ æ­¥éª¤ 1/5: åŠ è½½æœ¬åœ°èµ„æº...")
    assets_dir = 'assets'
    os.makedirs(assets_dir, exist_ok=True)
    
    urls_file = os.path.join(assets_dir, 'urls.txt')
    corrections_file = os.path.join(assets_dir, 'corrections_name.txt')

    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™åˆ›å»º
    if not os.path.exists(urls_file):
        with open(urls_file, 'w', encoding='utf-8') as f:
            f.write("# é»˜è®¤æº\nhttps://gcalic.v.myalicdn.com/gc/wgw05_1/index.m3u8\n")
    
    if not os.path.exists(corrections_file):
        with open(corrections_file, 'w', encoding='utf-8') as f:
            f.write("# é¢‘é“åç§°çº é”™æ–‡ä»¶\nCCTV1,å¤®è§†1å°,ä¸­å¤®1å°\næ¹–å—å«è§†,æ¹–å—ç”µè§†å°\n")

    urls_to_process = read_txt_to_array(urls_file)
    corrections = load_corrections(corrections_file)

    if not urls_to_process:
        print(f"âŒ é”™è¯¯: '{urls_file}' ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œç¨‹åºé€€å‡ºã€‚")
        return

    print(f"\nâ¡ï¸ æ­¥éª¤ 2/5: è·å– {len(urls_to_process)} ä¸ªåœ¨çº¿æº...")
    all_raw_channels = {}
    for url in tqdm(urls_to_process, desc="å¤„ç†æº"):
        try:
            content = fetch_source_content(url)
            if content:
                parsed_channels = parse_and_clean_channels(content, corrections)
                # åˆå¹¶ç›¸åŒé¢‘é“
                for name, url in parsed_channels.items():
                    if name in all_raw_channels:
                        # ä¿ç•™æ›´é•¿çš„URL
                        if len(url) > len(all_raw_channels[name]):
                            all_raw_channels[name] = url
                    else:
                        all_raw_channels[name] = url
        except Exception as e:
            print(f"âŒ å¤„ç†æºå¤±è´¥: {url} - {e}")
    
    print(f"\nâœ… æˆåŠŸè·å–å¹¶è§£æäº† {len(all_raw_channels)} ä¸ªä¸é‡å¤çš„é¢‘é“ã€‚")

    if not all_raw_channels:
        print("âŒ é”™è¯¯: æ²¡æœ‰è·å–åˆ°ä»»ä½•é¢‘é“ï¼Œç¨‹åºé€€å‡º")
        return

    print(f"\nâ¡ï¸ æ­¥éª¤ 3/5: æ£€æµ‹ {len(all_raw_channels)} ä¸ªé¢‘é“çš„æœ‰æ•ˆæ€§...")
    valid_channels = []
    total = len(all_raw_channels)
    
    with ThreadPoolExecutor(max_workers=50) as executor:
        futures = {executor.submit(check_channel_availability, (name, url)): (name, url) 
                   for name, url in all_raw_channels.items()}
        
        for future in tqdm(as_completed(futures), total=total, desc="æ£€æµ‹é¢‘é“"):
            try:
                name, url, latency = future.result()
                if latency >= 0:
                    valid_channels.append((name, url))
            except Exception:
                pass
    
    print(f"\nâœ… æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(valid_channels)} ä¸ªæœ‰æ•ˆé¢‘é“ã€‚")

    print("\nâ¡ï¸ æ­¥éª¤ 4/5: æ™ºèƒ½åˆ†ç±»é¢‘é“...")
    categorized_lists = {}
    
    for name, url in tqdm(valid_channels, desc="åˆ†ç±»é¢‘é“"):
        category = classify_channel(name)
        if category not in categorized_lists:
            categorized_lists[category] = []
        categorized_lists[category].append(f"{name},{url}")
    
    # æ‰“å°åˆ†ç±»ç»Ÿè®¡
    print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
    for cat_id, channels in categorized_lists.items():
        cat_name = "å…¶ä»–"
        for category_type in CATEGORY_CONFIG.values():
            for cid, info in category_type.items():
                if cid == cat_id:
                    cat_name = info["name"]
                    break
        print(f"  - {cat_name}: {len(channels)} ä¸ªé¢‘é“")
    print("âœ… åˆ†ç±»å®Œæˆã€‚")

    print("\nâ¡ï¸ æ­¥éª¤ 5/5: ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶...")
    total_saved = save_files(categorized_lists)

    print("\n--- ä»»åŠ¡å®Œæˆ ---")
    timeend = datetime.now()
    elapsed = timeend - timestart
    minutes, seconds = divmod(int(elapsed.total_seconds()), 60)
    print(f"ğŸ“Š æ€»è€—æ—¶: {minutes}åˆ† {seconds}ç§’")
    print(f"ğŸ“Š æ€»è®¡æœ‰æ•ˆé¢‘é“æ•°: {total_saved}")

if __name__ == "__main__":
    main()
